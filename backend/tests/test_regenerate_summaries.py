#!/usr/bin/env python3
"""
test_regenerate_summaries.py
é‡æ–°ç”Ÿæˆæœ€è¿‘ 10 ä¸ªè§†é¢‘çš„ AI æ‘˜è¦ï¼Œå¹¶éªŒè¯æ—¶é—´æˆ³æ˜¯å¦ä¸¥æ ¼é€’å¢ã€‚

ç”¨æ³•ï¼š
    # æ­£å¼æ‰§è¡Œï¼ˆå†™å…¥æ•°æ®åº“ + æœ¬åœ° JSONï¼‰
    python tests/test_regenerate_summaries.py

    # ä»…é¢„è§ˆï¼Œä¸å†™å…¥ä»»ä½•æ•°æ®
    python tests/test_regenerate_summaries.py --dry-run

    # æŒ‡å®šæ•°é‡ï¼ˆé»˜è®¤ 10ï¼‰
    python tests/test_regenerate_summaries.py --limit 5
"""

import os
import sys
import re
import json
import argparse
from datetime import datetime

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from dotenv import load_dotenv
load_dotenv(os.path.join(os.path.dirname(__file__), '../.env'))

from supabase import create_client, Client
from processor import summarize_text

# â”€â”€ Supabase è¿æ¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
supabase_url = os.environ.get("SUPABASE_URL")
supabase_key = os.environ.get("SUPABASE_SERVICE_KEY")
if not supabase_url or not supabase_key:
    print("âŒ ç¼ºå°‘ SUPABASE_URL æˆ– SUPABASE_SERVICE_KEY ç¯å¢ƒå˜é‡")
    sys.exit(1)

db: Client = create_client(supabase_url, supabase_key)

RESULTS_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '../results'))


# â”€â”€ å·¥å…·å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def ts_to_sec(ts_str: str) -> int:
    """å°† [MM:SS] æˆ– [HH:MM:SS] è½¬æ¢ä¸ºç§’æ•°ï¼ŒæœªåŒ¹é…è¿”å› -1ã€‚"""
    m = re.search(r'\[(\d{2}):(\d{2})(?::(\d{2}))?\]', ts_str)
    if not m:
        return -1
    if m.group(3):
        return int(m.group(1)) * 3600 + int(m.group(2)) * 60 + int(m.group(3))
    return int(m.group(1)) * 60 + int(m.group(2))


def check_timestamps_ordered(summary: str) -> tuple[bool, list[int]]:
    """
    æ£€æŸ¥æ‘˜è¦ä¸­å„è¡Œæ—¶é—´æˆ³æ˜¯å¦ä¸¥æ ¼é€’å¢ã€‚
    è¿”å› (is_ordered, [ç§’æ•°åˆ—è¡¨])
    """
    lines = [l for l in summary.split('\n') if l.strip()]
    seconds = []
    for line in lines:
        s = ts_to_sec(line)
        if s >= 0:
            seconds.append(s)
    if len(seconds) < 2:
        return True, seconds
    ordered = all(seconds[i] < seconds[i + 1] for i in range(len(seconds) - 1))
    return ordered, seconds


def build_full_text(paragraphs: list) -> str:
    """å°† paragraphs ç»“æ„è½¬æ¢ä¸ºå¸¦æ—¶é—´æˆ³çš„çº¯æ–‡æœ¬ï¼Œä¾› summarize_text ä½¿ç”¨ã€‚"""
    full_text = ""
    for p in paragraphs:
        for s in p.get("sentences", []):
            start_sec = int(s.get("start", 0))
            h, r = divmod(start_sec, 3600)
            mn, sv = divmod(r, 60)
            ts = f"[{h:02d}:{mn:02d}:{sv:02d}]" if h > 0 else f"[{mn:02d}:{sv:02d}]"
            full_text += f"{ts} {s.get('text', '')}\n"
    return full_text


def get_paragraphs(task: dict) -> list | None:
    """
    æŒ‰ä¼˜å…ˆçº§è·å– paragraphsï¼š
    1. æœ¬åœ° results/{task_id}.json
    2. Supabase report_data.paragraphs
    """
    task_id = task["id"]

    # ä¼˜å…ˆæœ¬åœ°æ–‡ä»¶
    local_path = os.path.join(RESULTS_DIR, f"{task_id}.json")
    if os.path.exists(local_path):
        with open(local_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        paragraphs = data.get("paragraphs", [])
        if paragraphs:
            return paragraphs, local_path, data

    # ä» Supabase report_data å–
    report = task.get("report_data") or {}
    paragraphs = report.get("paragraphs", [])
    if paragraphs:
        return paragraphs, None, report

    return None, None, None


# â”€â”€ ä¸»é€»è¾‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run(limit: int = 10, dry_run: bool = False):
    mode_label = "[DRY-RUN] " if dry_run else ""
    print(f"\n{'='*60}")
    print(f"  {mode_label}é‡æ–°ç”Ÿæˆæœ€è¿‘ {limit} ä¸ªè§†é¢‘çš„æ‘˜è¦")
    print(f"  æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")

    # æ‹‰å–æœ€è¿‘ N æ¡å·²å®Œæˆä»»åŠ¡
    resp = db.table("videos") \
        .select("id, title, report_data") \
        .eq("status", "completed") \
        .order("created_at", desc=True) \
        .limit(limit) \
        .execute()
    tasks = resp.data

    if not tasks:
        print("æœªæ‰¾åˆ°å·²å®Œæˆçš„ä»»åŠ¡ã€‚")
        return

    results = []

    for i, task in enumerate(tasks):
        task_id = task["id"]
        title = task.get("title", "ï¼ˆæ— æ ‡é¢˜ï¼‰")
        print(f"[{i+1}/{len(tasks)}] {task_id}  {title[:40]}")

        paragraphs, local_path, raw_data = get_paragraphs(task)
        if not paragraphs:
            print(f"         âš ï¸  æ‰¾ä¸åˆ° paragraphsï¼Œè·³è¿‡\n")
            results.append({"id": task_id, "title": title, "status": "skipped", "reason": "no paragraphs"})
            continue

        full_text = build_full_text(paragraphs)

        # ç”Ÿæˆæ–°æ‘˜è¦
        summary_data, usage = summarize_text(
            full_text,
            title=raw_data.get("title", title),
            description=raw_data.get("description", "")
        )
        new_summary = summary_data.get("summary", "")
        new_keywords = summary_data.get("keywords", [])

        if not new_summary:
            print(f"         âŒ  æ‘˜è¦ç”Ÿæˆå¤±è´¥\n")
            results.append({"id": task_id, "title": title, "status": "failed", "reason": "empty summary"})
            continue

        # éªŒè¯æ—¶é—´æˆ³é¡ºåº
        ordered, seconds = check_timestamps_ordered(new_summary)
        order_label = "âœ… æœ‰åº" if ordered else "âš ï¸  ä¹±åº"
        print(f"         æ—¶é—´æˆ³: {[f'{s//60:02d}:{s%60:02d}' for s in seconds]}  {order_label}")
        print(f"         æ¡ç›®æ•°: {len([l for l in new_summary.split(chr(10)) if l.strip()])}")

        if not dry_run:
            # æ›´æ–°æœ¬åœ° JSONï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if local_path and os.path.exists(local_path):
                with open(local_path, "r", encoding="utf-8") as f:
                    file_data = json.load(f)
                file_data["summary"] = new_summary
                file_data["keywords"] = new_keywords
                with open(local_path, "w", encoding="utf-8") as f:
                    json.dump(file_data, f, ensure_ascii=False, indent=2)
                print(f"         ğŸ’¾  æœ¬åœ° JSON å·²æ›´æ–°: {os.path.basename(local_path)}")

            # æ›´æ–° Supabase
            report = task.get("report_data") or {}
            report["summary"] = new_summary
            report["keywords"] = new_keywords
            db.table("videos").update({"report_data": report}).eq("id", task_id).execute()
            print(f"         â˜ï¸   Supabase å·²æ›´æ–°")
        else:
            print(f"         (dry-run: è·³è¿‡å†™å…¥)")

        results.append({
            "id": task_id,
            "title": title,
            "status": "ok",
            "timestamps_ordered": ordered,
            "item_count": len([l for l in new_summary.split('\n') if l.strip()]),
            "tokens": usage.get("total_tokens", 0)
        })
        print()

    # â”€â”€ æ±‡æ€»æŠ¥å‘Š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print(f"\n{'='*60}")
    print(f"  æ±‡æ€»æŠ¥å‘Š")
    print(f"{'='*60}")
    ok       = [r for r in results if r["status"] == "ok"]
    skipped  = [r for r in results if r["status"] == "skipped"]
    failed   = [r for r in results if r["status"] == "failed"]
    disordered = [r for r in ok if not r.get("timestamps_ordered", True)]

    print(f"  æˆåŠŸ:    {len(ok)}")
    print(f"  è·³è¿‡:    {len(skipped)}")
    print(f"  å¤±è´¥:    {len(failed)}")
    print(f"  æ—¶é—´ä¹±åº: {len(disordered)}")
    if disordered:
        print(f"  âš ï¸  ä»¥ä¸‹è§†é¢‘æ—¶é—´æˆ³ä»ä¹±åºï¼ˆAI æœªéµå®ˆæŒ‡ä»¤ï¼‰ï¼š")
        for r in disordered:
            print(f"     - {r['id']}  {r['title'][:40]}")
    else:
        print(f"  âœ…  æ‰€æœ‰æˆåŠŸè§†é¢‘æ—¶é—´æˆ³å‡ä¸ºé€’å¢é¡ºåº")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="é‡æ–°ç”Ÿæˆæœ€è¿‘ N ä¸ªè§†é¢‘çš„ AI æ‘˜è¦å¹¶éªŒè¯æ—¶é—´æˆ³é¡ºåº")
    parser.add_argument("--limit", type=int, default=10, help="å¤„ç†çš„è§†é¢‘æ•°é‡ï¼ˆé»˜è®¤ 10ï¼‰")
    parser.add_argument("--dry-run", action="store_true", help="ä»…é¢„è§ˆï¼Œä¸å†™å…¥ä»»ä½•æ•°æ®")
    args = parser.parse_args()
    run(limit=args.limit, dry_run=args.dry_run)
