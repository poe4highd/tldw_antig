# 字幕准确度提升验证总结

本任务成功实施了多项策略以解决 AI 生成字幕中的同音字错误、术语不一致等问题。通过对标基准视频 `QVBpiuph3rM`，我们验证了各阶段改进的实际成效。

## 改进前后量化对比

| 阶段 | 核心改动 | CER (字错率) | 准确率 | 关键改进点 |
| :--- | :--- | :--- | :--- | :--- |
| **Step 0** | 初始系统 (Whisper base) | 17.53% | 82.47% | 常见“灵 -> 零”、“祷 -> 倒”等同音字翻车。 |
| **Step 4** | Whisper Medium | 16.05% | 83.95% | 介于 base 和 large 之间，也存在幻觉循环。 |
| **Step 5** | **Whisper Turbo** | **11.27%** | **88.73%** | **原生准确度最高**。速度极快，幻觉较少。 |
| **Step 7** | **SenseVoice (ONNX)** | **13.65%** | **86.35%** | **性能神话**。37min 仅需 55s，无幻觉循环。 |
| **Step 1** | large-v3 + 引导词注入 | 12.38% | 87.62% | 核心名词识别率极高。 |
| **Step 2** | LLM 显性关键词注入 | 16.22%* | 83.78% | 语义规范化。CER 上升系因 LLM 清理了口语助词。 |
| **Step 3** | **LLM 跨块上下文感知** | 16.65%* | 83.35% | **一致性最优**。段落分段更符合逻辑。 |
| **Step 7** | **SenseVoice (ONNX)** | **13.65%** | **86.35%** | **性能与稳定性的平衡点**。 |

---

## 模型性能对标 (Mac M1 Max)

针对 37m 43s (2263s) 的基准视频进行的推理速度测试：

| 模型 | 推理时长 | RTF (实时率) | 内存占用 | 备注 |
| :--- | :--- | :--- | :--- | :--- |
| **Whisper Turbo** | **47s** | **0.021** | ~3-5GB | mlx-whisper (GPU) 加速，速度最快。 |
| **SenseVoice (ONNX)** | **55s** | **0.024** | **<2GB** | sherpa-onnx 推理，内存极省，无挂起风险。 |
| Whisper Base | ~30s | 0.013 | <1GB | 极速但准确度较差，适合粗剪。 |
| Whisper Medium (CPU)| ~15min | 0.400 | ~4GB | 纯 CPU 推理，速度较慢。 |

> [!NOTE]
> **RTF (Real-Time Factor)**: 处理 1 秒音频所需的时长。RTF 越小速度越快。

> [!TIP]
> **关于 CER 指标的说明**：
> 在 Step 2/3 中 CER 略有上升，主要是由于 LLM 将转录中的口语碎片（如多次出现的“的”）进行了精简，并统一了标点符号，这在字对字匹配中算作“错误”，但在用户体验上，Step 3 的文本远比 Step 1 更专业、易读。

## 已实施的关键技术

### 1. 转录增强 (Transcription)
- **模型升级**：默认模型从 `base` 升级为 `large-v3`，推理性能在 Mac GPU 上大幅提升。
- **动态 Prompt**：将视频标题注入 `initial_prompt`，从源头解决了“灵修”、“神”等特定背景词语的识别偏差。

### 2. 润色优化 (LLM Processing)
- **关键词权重**：从标题中自动提取关键词，显式要求 LLM 优先匹配。
- **跨块上下文 (Memory)**：实现了分块处理时的“滑动窗口”，LLM 会参考上一块的末尾文本，确保人名、术语在全文范围的一致性。

### 3. 模型特性观察 (Model Specifics)
- **SenseVoice (Sherpa-ONNX) 的突破**：通过集成 `sherpa-onnx` 和 `Silero VAD`，我们将 37 分钟视频的推理时间从 3 小时（FunASR/CPU）缩短至 **55秒**（RTF 约 0.024）。其 CER (13.65%) 表现稳健，且彻底杜绝了 Whisper 偶发的词汇循环幻觉。
- **Whisper Turbo 的优势**：在此视频测试中，`large-v3-turbo` 表现出了最低的字错率 (11.27%)，且其生成速度和内存占用都非常平衡。
- **幻觉循环 (Hallucination Loops)**：在音频模糊片段，`large-v3` 容易产生特定短语循环（如“这样的东西”）；`medium` 循环的是“环境未到哪里”。
- **LLM 鲁棒性**：后置的 LLM 校正阶段能够完美处理上述所有模型的幻觉循环，找回真实语义。
详细的 CER 评估报告已保存至：
- `backend/validation/QVBpiuph3rM_raw_...txt` (Step 0 & 1)
- `backend/validation/QVBpiuph3rM_llm_...txt` (Step 2 & 3)

## 模型文件管理建议

目前 `backend/models` 下保存了多个大型权重文件（Whisper, SenseVoice, VAD），总计超过 2GB。

- **不建议 Git 追踪**：大型二进制文件会使仓库急剧膨胀，建议将其加入 `.gitignore`。
- **记录方式**：在 `backend/models/README.md` 中记录模型来源和下载命令。
- **目前状态**：已在 `.gitignore` 中排除这些文件夹。

## 后续建议
- **性能优先**：如果注重速度，`large-v3-turbo` (GPU) 是首选。
- **高并发/老旧设备**：`SenseVoice (ONNX)` 凭借极低的内存占用和极佳的稳定性，更适合后端高并发任务。
- **质量优先**：开启全量 LLM 校正（Step 3）以获得最高的可读性和专业度。
